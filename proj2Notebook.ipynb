{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator\n",
    "from copy import deepcopy\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = './data/spliceATrainKIS.dat'\n",
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filepath) as fp:\n",
    "    line = fp.readline()\n",
    "    cnt = 1\n",
    "    while line:\n",
    "        data.append(line.strip())\n",
    "        line = fp.readline()\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11577,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutNr = int(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutNr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.reshape(a=data, newshape=(int(11576/2), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns=['y', \"seq\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.y = pd.to_numeric(df.y)\n",
    "classes = list(df.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = set(\"\".join([i for i in df.seq]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = np.array([list(i) for i in df.seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'C', 'G', 'N', 'S', 'T'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorytm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zbiór klas 'c'- czy jest prawdziwy czy nie (1 & 0)\n",
    "\n",
    "zbiór obiektów 's' - zbiór kolejnych przykładów\n",
    "\n",
    "zbiór atrybutów poza klasą 'r'- zbiór unikalnych liter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## częstość i-tej klasy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#znalezc ceche, ktora ma najwieksza czestosc\n",
    "p = [{c: 0 for c in attributes} for i in range(sequences.shape[1])]\n",
    "n = deepcopy(p)\n",
    "pAn = deepcopy(p)\n",
    "for ridx, row in enumerate(sequences):\n",
    "    for cidx, column in enumerate(row):\n",
    "        pAn[cidx][column] += 1\n",
    "        if df.y[ridx] == 1:\n",
    "            p[cidx][column] += 1\n",
    "        else:\n",
    "            n[cidx][column] += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mam zliczoną ilość wystąpień klejnych klas w danych numerach algorytmu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'C': 254, 'A': 262, 'G': 308, 'T': 290, 'N': 2, 'S': 0},\n",
       " {'C': 266, 'A': 265, 'G': 319, 'T': 263, 'N': 3, 'S': 0},\n",
       " {'C': 287, 'A': 255, 'G': 292, 'T': 281, 'N': 1, 'S': 0},\n",
       " {'C': 250, 'A': 260, 'G': 337, 'T': 268, 'N': 1, 'S': 0},\n",
       " {'C': 289, 'A': 255, 'G': 313, 'T': 258, 'N': 1, 'S': 0}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'C': 1160, 'A': 1007, 'G': 1361, 'T': 1143, 'N': 1, 'S': 0},\n",
       " {'C': 1135, 'A': 1052, 'G': 1293, 'T': 1192, 'N': 0, 'S': 0},\n",
       " {'C': 1185, 'A': 1039, 'G': 1270, 'T': 1178, 'N': 0, 'S': 0},\n",
       " {'C': 1182, 'A': 1037, 'G': 1255, 'T': 1197, 'N': 1, 'S': 0},\n",
       " {'C': 1164, 'A': 1046, 'G': 1276, 'T': 1185, 'N': 1, 'S': 0}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'C': 1414, 'A': 1269, 'G': 1669, 'T': 1433, 'N': 3, 'S': 0},\n",
       " {'C': 1401, 'A': 1317, 'G': 1612, 'T': 1455, 'N': 3, 'S': 0},\n",
       " {'C': 1472, 'A': 1294, 'G': 1562, 'T': 1459, 'N': 1, 'S': 0},\n",
       " {'C': 1432, 'A': 1297, 'G': 1592, 'T': 1465, 'N': 2, 'S': 0},\n",
       " {'C': 1453, 'A': 1301, 'G': 1589, 'T': 1443, 'N': 2, 'S': 0}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pAn[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id3(classes, attributes, sequences):\n",
    "    \"\"\"\n",
    "    c- list of classes\n",
    "    r- list of atributes\n",
    "    s- list of objects\n",
    "    \"\"\"\n",
    "    if not sequences:\n",
    "        return -1\n",
    "    if classes.count(classes[0]) == len(x):\n",
    "        return classes[0]\n",
    "    if not attributes:\n",
    "        stats = {label: list(classes).count(label)  for label in np.unique(classes)}\n",
    "        max(stats.items(), key=operator.itemgetter(1))[0]\n",
    "    #atrybut maksymalizujący InfGain(D, S)\n",
    "    d = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## atrybut maksimalizujący infGain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### entropia zbioru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\n",
      "T\n",
      "S\n",
      "A\n",
      "C\n",
      "G\n"
     ]
    }
   ],
   "source": [
    "testD = {'N': 1, 'T': 1143, 'S': 0, 'A': 1007, 'C': 1160, 'G': 1361}\n",
    "for i in testD:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_frequency(pAn):\n",
    "    \"\"\"\n",
    "    p = list of dictionaries caunting positive\n",
    "    n - list of dictionaries counting negative\n",
    "    y - output (0, 1)\n",
    "    \"\"\"\n",
    "    totalInRow = [sum(row.values()) for row in pAn]\n",
    "    frequencies = deepcopy(pAn)\n",
    "    for row, rowSum in zip(frequencies, totalInRow):\n",
    "        for key in row:\n",
    "            row[key] = row[key]/rowSum\n",
    "    return frequencies\n",
    "frequencies = calculate_frequency(pAn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropyLabel(labels):\n",
    "    p = 0\n",
    "    n = 0\n",
    "    for ridx, row in enumerate(labels):\n",
    "        if row == 1:\n",
    "            p += 1\n",
    "        else:\n",
    "            n += 1\n",
    "    pf = p/len(labels)\n",
    "    nf = n/len(labels)\n",
    "    entropy = -pf*log(pf, 2)-nf*log(nf, 2)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropyL = calculate_entropyLabel(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "policzyc entropy dla outlook z przykładu zeby sprawdzic dzialanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def singleEntropy(f, nrF):\n",
    "    return -f*log(f, nrF)\n",
    "def entropy(e1, e2, *rest):\n",
    "    args = np.concatenate(([e1, e2], rest)).astype(float) \n",
    "    fs = [arg/sum(args) for arg in args]\n",
    "    return sum([singleEntropy(f, len(fs)) for f in fs])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def informationGain(class1, class2, e1pair, e2pair, *rest):\n",
    "    es = entropy(class1, class2)\n",
    "#     eArgsP = np.concatenate(([e1pair, e2pair], rest)).astype(float)\n",
    "    eArgsP = np.array([e1pair, e2pair]).astype(float)\n",
    "    eArgs = [sum(e) for e in eArgsP]\n",
    "    fs = [arg/sum(eArgs) for arg in eArgs]\n",
    "    fsAtributes = [[value/sum(attribute) for value in attribute] for attribute in eArgsP]\n",
    "    entropies = [entropy(value[0], value[1]) for value in fsAtributes]\n",
    "    print(fs)\n",
    "    print(fsAtributes)\n",
    "    print(entropies)\n",
    "    return sum([entropy*f for f, entropy in zip(fs, entropies)])\n",
    "#     eSA = [[for ] for fs, entropy in zip(fsAtributes, entropies)]\n",
    "#     return es-sum(eSA)\n",
    "#     [f*entropy() for f in zip(fs, )]\n",
    "#     eSA = sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5714285714285714, 0.42857142857142855]\n",
      "[[0.75, 0.25], [0.5, 0.5]]\n",
      "[0.8112781244591328, 1.0]\n"
     ]
    }
   ],
   "source": [
    "informationGain(9, 5, (6, 2), (3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "informationGain(0.94, 8,  6, eW, eS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = [1, 2, 3, 4]\n",
    "[arg/ for idx, arg in enumerate(lista)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
